base_config: &BASE_CONFIG
    random_seed: 42
    # log_test_interval: 100

transformer: &TRANSFORMER
    <<: *BASE_CONFIG
    # binary operation
    operation: 'x+y'
    prime: 97
    training_fraction: 0.5
    optimizer: 'adamw'

    # transformer parameters
    num_layers: 2
    dim_model: 128
    num_heads: 4
    batch_size: 512
    learning_rate: 0.001
    weight_decay: 1
    dropout: 0.0
    epochs: 10000

mlp: &mlp
    <<: *BASE_CONFIG
    operation: 'x+y'
    prime: 97
    training_fraction: 0.8  # Reduced to induce grokking
    num_layers: 3
    dim_model: 128
    embedding_size: 10
    dropout: 0.0
    epochs: 10000
    batch_size: 128
    learning_rate: 0.0004
    weight_decay: 0.01
    # random_seed: 42

LSTM: &LSTM
    <<: *BASE_CONFIG
    # binary operation
    operation: 'x+y'
    prime: 97
    training_fraction: 0.5

    # LSTM parameters
    epochs: 1000