base_config: &BASE_CONFIG
    random_seed: 42
    # log_test_interval: 100

transformer: &TRANSFORMER
    <<: *BASE_CONFIG
    # binary operation
    operation: 'x+y'
    prime: 97
    training_fraction: 0.5
    optimizer: 'adamw'

    # transformer parameters
    num_layers: 2
    dim_model: 128
    num_heads: 4
    batch_size: 512
    learning_rate: 0.001
    weight_decay: 1
    dropout: 0.0
    epochs: 10000

mlp: &mlp
    <<: *BASE_CONFIG
    # binary operation
    operation: 'x+y'
    prime: 97
    training_fraction: 0.5

    # MLP parameters
    num_layers: 3  # Number of layers in the MLP
    dim_model: 128  # Hidden layer size
    dropout: 0.1  # Dropout probability
    epochs: 10000
    batch_size: 256
    learning_rate: 0.001
    weight_decay: 1

LSTM: &LSTM
    <<: *BASE_CONFIG
    # binary operation
    operation: 'x+y'
    prime: 97
    training_fraction: 0.5

    # LSTM parameters
    epochs: 1000